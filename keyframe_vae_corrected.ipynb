{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreshth-112/Video-summarization-using-keyframe-extraction/blob/main/keyframe_vae_corrected.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd3b15e",
      "metadata": {
        "id": "edd3b15e"
      },
      "source": [
        "# Loading Ground truth frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dc3ee79",
      "metadata": {
        "id": "3dc3ee79"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import cv2\n",
        "\n",
        "# Load the MAT file\n",
        "mat_file = scipy.io.loadmat(\"D:\\College etc\\College\\8th sem\\Project\\SumMe\\GT\\Cooking.mat\")\n",
        "\n",
        "# Extract the segments information from the MAT file\n",
        "segments = mat_file['segments'][0]  # Assuming the segments information is stored as a cell array\n",
        "\n",
        "# Load the video file\n",
        "video = cv2.VideoCapture(\"Cooking.mp4\")\n",
        "\n",
        "# Extract keyframes from each segment\n",
        "keyframes = []\n",
        "for segment in segments:\n",
        "    start_frame = int(segment[0][0])  # Convert start frame index to integer\n",
        "    end_frame = int(segment[0][1])  # Convert end frame index to integer\n",
        "\n",
        "    # Extract keyframes within the segment range\n",
        "    for frame_index in range(start_frame, end_frame + 1):\n",
        "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_index)  # Set the video frame position to the current frame index\n",
        "        ret, frame = video.read()\n",
        "        if ret:\n",
        "            keyframes.append(frame)\n",
        "\n",
        "# Save the keyframes as individual image files or perform further processing\n",
        "\n",
        "# Release the video file\n",
        "video.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "345d8f4c",
      "metadata": {
        "id": "345d8f4c"
      },
      "source": [
        "## Keyframe extraction for video summarisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e71d5c6d",
      "metadata": {
        "id": "e71d5c6d",
        "outputId": "78940097-e769-4d6c-9f0d-4a746d41eead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 99s 2s/step\n"
          ]
        }
      ],
      "source": [
        "# Import the required libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "\n",
        "# Load the video file\n",
        "video = cv2.VideoCapture(\"Cooking.mp4\")\n",
        "\n",
        "# Define the VAE model architecture\n",
        "input_shape = (640, 640, 3)\n",
        "latent_dim = 256\n",
        "\n",
        "def vae_model():\n",
        "    input_img = Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = Conv2D(latent_dim, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "    # Latent representation\n",
        "    flat = tf.keras.layers.Flatten()(x)\n",
        "    encoded = tf.keras.layers.Dense(latent_dim, activation='relu')(flat)\n",
        "    encoder = Model(input_img, encoded)\n",
        "\n",
        "    # Decoder\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # VAE model\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    return autoencoder, encoder\n",
        "\n",
        "# Create a KMeans clustering object\n",
        "n_clusters = 30\n",
        "kmeans = KMeans(n_clusters=n_clusters)\n",
        "\n",
        "# Train the VAE model\n",
        "autoencoder, encoder = vae_model()\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Extract frames from the video\n",
        "frames = []\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame = cv2.resize(frame, (640, 640))\n",
        "    frames.append(frame)\n",
        "frames = np.array(frames)\n",
        "\n",
        "# Extract the latent representation of the frames\n",
        "encoded_frames = encoder.predict(frames)\n",
        "\n",
        "# Cluster the latent representations using KMeans\n",
        "kmeans.fit(encoded_frames)\n",
        "\n",
        "# Extract the keyframes\n",
        "keyframes = []\n",
        "for i in range(n_clusters):\n",
        "    cluster_indices = np.where(kmeans.labels_ == i)[0]\n",
        "    cluster_frames = frames[cluster_indices]\n",
        "    cluster_distances = kmeans.transform(encoded_frames[cluster_indices])\n",
        "    keyframe_index = np.argmin(np.max(cluster_distances, axis=1))\n",
        "    keyframe = cluster_frames[keyframe_index]\n",
        "    keyframes.append(keyframe)\n",
        "\n",
        "# Save the keyframes as an MP4 video\n",
        "height, width, layers = keyframes[0].shape\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "video_writer = cv2.VideoWriter('keyframes_cook.mp4', fourcc, 30, (width, height))\n",
        "for frame in keyframes:\n",
        "    video_writer.write(frame)\n",
        "video_writer.release()\n",
        "\n",
        "# Release the video file\n",
        "video.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84c71999",
      "metadata": {
        "id": "84c71999"
      },
      "source": [
        "## Calcluating SSIM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f66adaef",
      "metadata": {
        "id": "f66adaef",
        "outputId": "509122f2-2e56-4a38-dded-ce1518a64e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SSIM: 0.9771203464670698\n",
            "SSIM: 0.981167755327745\n",
            "SSIM: 0.9766605533964451\n",
            "SSIM: 0.9828939196569944\n",
            "SSIM: 0.9843180626916304\n",
            "SSIM: 0.9805899616481492\n",
            "SSIM: 0.9797184550289161\n",
            "SSIM: 0.9796338490729566\n",
            "SSIM: 0.9783998935257417\n",
            "SSIM: 0.9795186360366318\n",
            "SSIM: 0.9812017031879224\n",
            "SSIM: 0.9808075843688635\n",
            "SSIM: 0.9846464992743256\n",
            "SSIM: 0.9807443122321227\n",
            "SSIM: 0.9816415996355486\n",
            "SSIM: 0.9810423921162751\n",
            "SSIM: 0.9824884913287779\n",
            "SSIM: 0.9816452474669005\n",
            "SSIM: 0.9804515196059042\n",
            "SSIM: 0.9818186394673101\n",
            "SSIM: 0.9798226403418732\n",
            "SSIM: 0.9827327171383569\n",
            "SSIM: 0.9808836308997407\n",
            "SSIM: 0.9809050682591994\n",
            "SSIM: 0.9811758232375432\n",
            "SSIM: 0.9769646041582646\n",
            "SSIM: 0.9813404210694728\n",
            "SSIM: 0.978958284637155\n",
            "SSIM: 0.9794789723234867\n",
            "SSIM: 0.9787712802436588\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Load the extracted keyframes from your code\n",
        "extracted_keyframes = []\n",
        "\n",
        "video = cv2.VideoCapture('keyframes_cook.mp4')\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    extracted_keyframes.append(frame)\n",
        "video.release()\n",
        "\n",
        "# Load the ground truth keyframes from your code\n",
        "ground_truth_keyframes = keyframes  # Replace 'keyframes' with the variable name storing the ground truth keyframes\n",
        "\n",
        "# Compare each keyframe\n",
        "for extracted_frame, ground_truth_frame in zip(extracted_keyframes, ground_truth_keyframes):\n",
        "    # Convert frames to grayscale for SSIM comparison\n",
        "    extracted_frame_gray = cv2.cvtColor(extracted_frame, cv2.COLOR_BGR2GRAY)\n",
        "    ground_truth_frame_gray = cv2.cvtColor(ground_truth_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculate SSIM between keyframes\n",
        "    similarity = ssim(extracted_frame_gray, ground_truth_frame_gray)\n",
        "\n",
        "    # Print the similarity value\n",
        "    print(f\"SSIM: {similarity}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}